Lecture Notes: Week 7 - Multiple Comparisons
========================================================

# The Z Statistic:
```{r}
# install.packages("xtable")
library(xtable)
```

Lecture example: We have a small kitten, what is the chance of picking up another random kitten that is smaller?

Z = Kitten height minus average kitten height divided by kitten population standard deviation

Here is the formal formula

$$H_0 : Z \thicksim N(0,1) $$
$$p_1 = P(Z \leq Z_1|H_0) \equiv \Phi(Z_1)$$

In plain english it means that the Z statistic is approximately normal (zero to one). When it is normal, define $$\Phi$$ as the probability that we observe a measurement smaller than the observation in question ($$Z_1$$) under the null hypothesis assuming a normal distribution. In R this is pnorm()

## Example small Z scores

We are describing the population of Z values under the null hypothesis...

$$P(p \lt p_1) = P(\Phi(Z) \leq \Phi(Z_1)) = P(Z \leq Z_1) = p_1$$

This shows that the Z transformation maps the Z statistic to its probability $$p_1$$, which is a uniform distribution. So this transformation tells us in other words what we already know. The P value is going to give us false positives, and in genomics, with a large number of experiments, the number of false positives increase with the number of experiments (20,000 experiments and P-value of .001 = 20 FP). So whoopdy doo, what's in the next section?

# Video 2: Combining Null and Non-null tests

# Video 3: Multiple Hypothesis Testing

P-values suck. 

## Definitions of error

Type I = P(called sygnificatnt | null is true)
Type II = P(Not called sygnificant | null is false)

In genomics, 

```{r}
tab <- cbind(c("", "Null True", "Altern.True", "Total"), c("Called Significatn", "V", "S", "R"), c("Not Called Significant", "$$m_0 - V$$", "$$m_1 - S$$", "$$m - R$$"), c("Total", "$$m_0$$", "$$m_1$$", "$$m$$"))
tab
#xtable(tab)
```

with one test

$$P(V = 1|m_0 = 1) \equiv p-value$$

but with m >> 1, then this falls apart

## Family-wise Error Rate (FWER)

What is probablility of m = x when v = b - a specific FP rate for given n experiments

Conservative approach used in GWAs

## Bonferroni Correction

list of samples for this set will be genes with p-values less than:

$$ max \{ p_i : p_i \leq \frac{\alpha}{m} \}$$

$$ typically: \alpha = 0.05 $$

$$ P(V \geq 1) \leq P ( min_i(p_i \leq \frac{\alpha}{m} | H_0^{(m_1 = 0)}) $$

$$ \leq \sigma_{i=1}^m P ( p_i \leq \frac{\alpha}{m} | H_0^i ) $$

$$ = m \frac{\alpha}{m} $$

This is no good for discovery experiments

# False Discovery Rate (FDR)

Don't control the FWER, instead control the percent of mistakes in the data.

$$ FDR = \frac{false positives}{false negatives} = \frac{V}{V+S} = \frac{V}{R} $$

Don't know V, have to estimate.

## Benjamini-Hochberg (1995)

order P-values from smalles to largest $p(i)$, then let $k$ be the largest index $i$ for which 

$$p(i)$ \leq \frac{i}{m}\alpha$$

Then reject $H_{(i)}$ for $i = 1,\dots,k$

### Visual interpretation

Choose points under line.

```{r}
x = seq(1,100,1)
y = x / 100
y[1] = 0.0001
y[2] = 0.0001
y[3] = 0.0002
y[4] = 0.0005
y[5] = 0.0005
y[6] = 0.0006
plot(x, y, xlab="i", ylab="p-value", main="alpha = 0.05")
abline(0, 0.05 / 100)

plot(x, y, xlab="i", ylab="p-value", main="alpha = 0.05", xlim=c(0,20))
abline(0, 0.05 / 100)
```

Gives expected FDR < 0.05 (or $\alpha$)

## Direct approach (Storey 2002)

Less conservative

let $k$ be the largest $i$ such that $\pi_0p_{(i)} \leq \frac{i}{m}\alpha$ and reject $H_{(i)}$ for $i = 1,\dots,k$

Degenerates to B-H at $\pi_0 = 1$

## FDR and q-value

*FDR is a property of a list, the q-value is a property of a member of that list. it is the smallest FDR which would include the member of the list. in GWAs, the list member is a single gene.*



